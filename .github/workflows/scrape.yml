name: Twitter Scraper with Sentiment

on:
  schedule:
    - cron: "0 0 * * *" # 每天 UTC 0 点运行
  workflow_dispatch:     # 允许手动运行

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: pip install snscrape pandas vaderSentiment
      - name: Run scraper
        run: python tweet_scraper_with_sentiment.py
      - name: Commit and push results
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "actions@github.com"
          git add tweets_dataset.csv
          git commit -m "Update tweets dataset" || echo "No changes"
          git push
